#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import aiomysql
import json
from datetime import datetime
from collections import defaultdict
from config.db_config import *

class CommentTreeAnalyzer:
    """è¯„è®ºæ ‘ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        self.conn = None
    
    async def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = await aiomysql.connect(
            host=RELATION_DB_HOST,
            port=RELATION_DB_PORT,
            user=RELATION_DB_USER,
            password=RELATION_DB_PWD,
            db=RELATION_DB_NAME,
            charset='utf8mb4'
        )
    
    async def close_db(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            await self.conn.ensure_closed()
    
    async def get_comments_by_note(self, note_id):
        """è·å–æŒ‡å®šç¬”è®°çš„æ‰€æœ‰è¯„è®º"""
        cursor = await self.conn.cursor()
        await cursor.execute("""
            SELECT comment_id, note_id, content, nickname, like_count, 
                   create_time, sub_comment_count, parent_comment_id, avatar
            FROM xhs_note_comment 
            WHERE note_id = %s
            ORDER BY create_time ASC
        """, (note_id,))
        
        comments = await cursor.fetchall()
        await cursor.close()
        
        return [
            {
                'comment_id': row[0],
                'note_id': row[1],
                'content': row[2],
                'nickname': row[3],
                'like_count': int(row[4]) if row[4] else 0,
                'create_time': row[5],
                'sub_comment_count': int(row[6]) if row[6] else 0,
                'parent_comment_id': row[7] if row[7] != '0' else None,
                'avatar': row[8]
            }
            for row in comments
        ]
    
    def build_comment_tree(self, comments):
        """æ„å»ºè¯„è®ºæ ‘ç»“æ„"""
        # æŒ‰parent_comment_idåˆ†ç»„
        comments_by_parent = defaultdict(list)
        comment_map = {}
        
        for comment in comments:
            comment_map[comment['comment_id']] = comment
            parent_id = comment['parent_comment_id']
            comments_by_parent[parent_id].append(comment)
        
        # æ„å»ºæ ‘ç»“æ„
        def build_tree_recursive(parent_id=None):
            tree = []
            for comment in comments_by_parent[parent_id]:
                comment_node = comment.copy()
                comment_node['replies'] = build_tree_recursive(comment['comment_id'])
                comment_node['reply_count'] = len(comment_node['replies'])
                tree.append(comment_node)
            return tree
        
        return build_tree_recursive()
    
    def format_comment_tree_text(self, tree, indent=0):
        """æ ¼å¼åŒ–è¯„è®ºæ ‘ä¸ºæ–‡æœ¬æ˜¾ç¤º"""
        result = []
        
        for comment in tree:
            prefix = "  " * indent + ("â””â”€ " if indent > 0 else "")
            
            # æ ¼å¼åŒ–æ—¶é—´
            create_time = comment['create_time']
            if isinstance(create_time, int):
                time_str = datetime.fromtimestamp(create_time / 1000).strftime('%Y-%m-%d %H:%M')
            else:
                time_str = str(create_time)
            
            # ä¸»è¯„è®ºä¿¡æ¯
            result.append(f"{prefix}ğŸ‘¤ {comment['nickname']}")
            result.append(f"{prefix}ğŸ’¬ {comment['content']}")
            result.append(f"{prefix}â¤ï¸ {comment['like_count']} ğŸ‘¥ {comment['reply_count']} â° {time_str}")
            result.append("")
            
            # é€’å½’æ˜¾ç¤ºå›å¤
            if comment['replies']:
                result.extend(self.format_comment_tree_text(comment['replies'], indent + 1))
        
        return result
    
    async def analyze_note_comments(self, note_id):
        """åˆ†ææŒ‡å®šç¬”è®°çš„è¯„è®ºç»“æ„"""
        print(f"ğŸ” åˆ†æç¬”è®° {note_id} çš„è¯„è®ºç»“æ„...")
        
        # è·å–è¯„è®ºæ•°æ®
        comments = await self.get_comments_by_note(note_id)
        
        if not comments:
            print("âŒ æœªæ‰¾åˆ°è¯„è®ºæ•°æ®")
            return None
        
        # æ„å»ºè¯„è®ºæ ‘
        comment_tree = self.build_comment_tree(comments)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_comments = len(comments)
        top_level_comments = len(comment_tree)
        reply_comments = total_comments - top_level_comments
        
        # è®¡ç®—å„å±‚çº§è¯„è®ºæ•°é‡
        level_counts = defaultdict(int)
        
        def count_levels(tree, level=0):
            level_counts[level] += len(tree)
            for comment in tree:
                if comment['replies']:
                    count_levels(comment['replies'], level + 1)
        
        count_levels(comment_tree)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        analysis = {
            'note_id': note_id,
            'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'statistics': {
                'total_comments': total_comments,
                'top_level_comments': top_level_comments,
                'reply_comments': reply_comments,
                'max_depth': max(level_counts.keys()) if level_counts else 0,
                'level_distribution': dict(level_counts)
            },
            'comment_tree': comment_tree
        }
        
        return analysis
    
    async def get_hot_notes_with_comments(self, limit=5):
        """è·å–æœ‰è¯„è®ºçš„çƒ­é—¨ç¬”è®°"""
        cursor = await self.conn.cursor()
        await cursor.execute("""
            SELECT DISTINCT n.note_id, n.title, n.liked_count, n.comment_count, 
                   COUNT(c.comment_id) as actual_comment_count
            FROM xhs_note n
            LEFT JOIN xhs_note_comment c ON n.note_id = c.note_id
            GROUP BY n.note_id, n.title, n.liked_count, n.comment_count
            HAVING actual_comment_count > 0
            ORDER BY CAST(n.liked_count AS UNSIGNED) DESC
            LIMIT %s
        """, (limit,))
        
        notes = await cursor.fetchall()
        await cursor.close()
        
        return [
            {
                'note_id': row[0],
                'title': row[1],
                'liked_count': row[2],
                'comment_count': row[3],
                'actual_comment_count': row[4]
            }
            for row in notes
        ]

async def main():
    """ä¸»å‡½æ•°"""
    analyzer = CommentTreeAnalyzer()
    
    try:
        # è¿æ¥æ•°æ®åº“
        await analyzer.connect_db()
        
        print("ğŸ¯ å°çº¢ä¹¦è¯„è®ºç»“æ„åˆ†æå·¥å…·")
        print("=" * 60)
        
        # è·å–æœ‰è¯„è®ºçš„çƒ­é—¨ç¬”è®°
        hot_notes = await analyzer.get_hot_notes_with_comments(10)
        
        if not hot_notes:
            print("âŒ æœªæ‰¾åˆ°æœ‰è¯„è®ºçš„ç¬”è®°æ•°æ®")
            return
        
        print("ğŸ“Š çƒ­é—¨ç¬”è®°åˆ—è¡¨:")
        for i, note in enumerate(hot_notes, 1):
            print(f"{i}. {note['title'][:40]}...")
            print(f"   ç¬”è®°ID: {note['note_id']}")
            print(f"   ç‚¹èµ: {note['liked_count']} | è¯„è®º: {note['actual_comment_count']}")
            print()
        
        # åˆ†æå‰3ä¸ªç¬”è®°çš„è¯„è®ºç»“æ„
        print("ğŸ” è¯¦ç»†åˆ†æå‰3ä¸ªç¬”è®°çš„è¯„è®ºç»“æ„:")
        print("=" * 60)
        
        for i, note in enumerate(hot_notes[:3], 1):
            print(f"\nğŸ“ ç¬”è®° {i}: {note['title'][:30]}...")
            print("-" * 50)
            
            # åˆ†æè¯„è®ºç»“æ„
            analysis = await analyzer.analyze_note_comments(note['note_id'])
            
            if analysis:
                stats = analysis['statistics']
                print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                print(f"   æ€»è¯„è®ºæ•°: {stats['total_comments']}")
                print(f"   é¡¶çº§è¯„è®º: {stats['top_level_comments']}")
                print(f"   å›å¤è¯„è®º: {stats['reply_comments']}")
                print(f"   æœ€å¤§æ·±åº¦: {stats['max_depth']}")
                print(f"   å„å±‚åˆ†å¸ƒ: {stats['level_distribution']}")
                print()
                
                # æ˜¾ç¤ºè¯„è®ºæ ‘ç»“æ„ï¼ˆå‰10æ¡ï¼‰
                if analysis['comment_tree']:
                    print("ğŸŒ² è¯„è®ºæ ‘ç»“æ„ï¼ˆå‰10æ¡ï¼‰:")
                    tree_text = analyzer.format_comment_tree_text(analysis['comment_tree'][:10])
                    for line in tree_text[:50]:  # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°
                        print(line)
                    
                    if len(tree_text) > 50:
                        print("... (æ›´å¤šè¯„è®ºçœç•¥)")
                
                # ä¿å­˜è¯¦ç»†åˆ†æåˆ°æ–‡ä»¶
                filename = f'data/comment_analysis_{note["note_id"]}.json'
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
                print(f"ğŸ’¾ è¯¦ç»†åˆ†æå·²ä¿å­˜åˆ°: {filename}")
                print()
        
        # ç”Ÿæˆæ€»ä½“ç»Ÿè®¡æŠ¥å‘Š
        print("ğŸ“ˆ ç”Ÿæˆæ€»ä½“è¯„è®ºç»Ÿè®¡æŠ¥å‘Š...")
        
        cursor = await analyzer.conn.cursor()
        
        # è¯„è®ºæ€»ä½“ç»Ÿè®¡
        await cursor.execute("""
            SELECT 
                COUNT(*) as total_comments,
                COUNT(CASE WHEN parent_comment_id IS NULL OR parent_comment_id = '0' THEN 1 END) as top_level,
                COUNT(CASE WHEN parent_comment_id IS NOT NULL AND parent_comment_id != '0' THEN 1 END) as replies,
                AVG(CAST(like_count AS UNSIGNED)) as avg_likes,
                MAX(CAST(like_count AS UNSIGNED)) as max_likes
            FROM xhs_note_comment
        """)
        
        stats = await cursor.fetchone()
        
        overall_report = {
            'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'overall_statistics': {
                'total_comments': int(stats[0]),
                'top_level_comments': int(stats[1]),
                'reply_comments': int(stats[2]),
                'average_likes': round(float(stats[3] or 0), 2),
                'max_likes': int(stats[4] or 0)
            },
            'hot_notes': hot_notes
        }
        
        # ä¿å­˜æ€»ä½“æŠ¥å‘Š
        with open('data/comment_overall_report.json', 'w', encoding='utf-8') as f:
            json.dump(overall_report, f, ensure_ascii=False, indent=2, default=str)
        
        print("âœ… æ€»ä½“æŠ¥å‘Šå·²ä¿å­˜åˆ°: data/comment_overall_report.json")
        
        print("\nğŸ‰ è¯„è®ºç»“æ„åˆ†æå®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“Š æ€»è¯„è®ºæ•°: {overall_report['overall_statistics']['total_comments']}")
        print(f"ğŸ” é¡¶çº§è¯„è®º: {overall_report['overall_statistics']['top_level_comments']}")
        print(f"ğŸ’¬ å›å¤è¯„è®º: {overall_report['overall_statistics']['reply_comments']}")
        print(f"â¤ï¸ å¹³å‡ç‚¹èµ: {overall_report['overall_statistics']['average_likes']}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await analyzer.close_db()

if __name__ == '__main__':
    # ç¡®ä¿dataç›®å½•å­˜åœ¨
    import os
    os.makedirs('data', exist_ok=True)
    
    asyncio.run(main())
